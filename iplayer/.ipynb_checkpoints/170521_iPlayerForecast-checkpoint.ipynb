{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast the minutes watched by a viewer in the next two weeks given their viewing behaviour over the last 16 weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data for about 10,000 viewers of iPlayer that tells us when they watched what programme. We will use this data to try and see whether we can predict how 'loyal' a viewer is. We have no data about the viewers themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all relevent libraries to analyse the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set options to display all columns\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data and preprocess for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>program_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>programme_duration</th>\n",
       "      <th>streaming_id</th>\n",
       "      <th>start_date_time</th>\n",
       "      <th>time_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>f6d3d8</td>\n",
       "      <td>a282ca</td>\n",
       "      <td>Factual</td>\n",
       "      <td>00:00:21</td>\n",
       "      <td>1486911129420_1</td>\n",
       "      <td>2017-02-12 14:51:24.544</td>\n",
       "      <td>20920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>b8fbf2</td>\n",
       "      <td>e0480e</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>00:01:51</td>\n",
       "      <td>1484864257965_1</td>\n",
       "      <td>2017-01-19 22:17:04.648</td>\n",
       "      <td>111285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>e2f113</td>\n",
       "      <td>933a1b</td>\n",
       "      <td>Factual</td>\n",
       "      <td>00:00:30</td>\n",
       "      <td>1487099603980_1</td>\n",
       "      <td>2017-02-14 19:12:36.667</td>\n",
       "      <td>29945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>0e0916</td>\n",
       "      <td>b68e79</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>00:01:22</td>\n",
       "      <td>1484773546557_1</td>\n",
       "      <td>2017-01-18 21:05:11.466</td>\n",
       "      <td>82620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>ca03b9</td>\n",
       "      <td>5d0813</td>\n",
       "      <td>Sport</td>\n",
       "      <td>00:01:37</td>\n",
       "      <td>1486911176609_1</td>\n",
       "      <td>2017-02-12 14:52:08.965</td>\n",
       "      <td>97444.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id program_id series_id          genre programme_duration  \\\n",
       "0  cd2006     f6d3d8    a282ca        Factual           00:00:21   \n",
       "1  cd2006     b8fbf2    e0480e         Comedy           00:01:51   \n",
       "2  cd2006     e2f113    933a1b        Factual           00:00:30   \n",
       "3  cd2006     0e0916    b68e79  Entertainment           00:01:22   \n",
       "4  cd2006     ca03b9    5d0813          Sport           00:01:37   \n",
       "\n",
       "      streaming_id         start_date_time  time_viewed  \n",
       "0  1486911129420_1 2017-02-12 14:51:24.544      20920.0  \n",
       "1  1484864257965_1 2017-01-19 22:17:04.648     111285.0  \n",
       "2  1487099603980_1 2017-02-14 19:12:36.667      29945.0  \n",
       "3  1484773546557_1 2017-01-18 21:05:11.466      82620.0  \n",
       "4  1486911176609_1 2017-02-12 14:52:08.965      97444.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a pandas dataframe and display first couple of rows to see what it looks like\n",
    "data=pd.read_csv('iplayer_data_sample_janapr2017.csv', parse_dates=['start_date_time'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enhance the data with a few additional columns that make it easier to analyse the data \n",
    "\n",
    "# Get the weekday\n",
    "def get_weekday(formated_time):\n",
    "    return 'weekday_' + str(formated_time.weekday())\n",
    "\n",
    "# Get the two-week number. We will forecast the minutes watched in the last two weeks\n",
    "# Python3 rounds 0.5 up and down depending on the integer so we can't use round function\n",
    "def get_twoweeknumber(formated_time):\n",
    "    return math.floor(formated_time.isocalendar()[1]/2.0)\n",
    "\n",
    "\n",
    "# Get the time of day\n",
    "def get_timeofday(formated_time):\n",
    "    hour=formated_time.hour\n",
    "    if hour in range(5,13):\n",
    "        return 'Morning'\n",
    "    elif hour in range(13,18):\n",
    "        return 'Afternoon'\n",
    "    elif hour in range(18,23):\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "# Parse the programme duration and turn it into minutes so that we can compute the percentage of time watched\n",
    "def parse_programme_duration(unformated_time):\n",
    "    try:\n",
    "        timeparts=unformated_time.split(':')\n",
    "        return int(timeparts[0])*60.0+int(timeparts[1])+int(timeparts[2])/60.0\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>program_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>programme_duration</th>\n",
       "      <th>streaming_id</th>\n",
       "      <th>start_date_time</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>programme_duration_mins</th>\n",
       "      <th>twoweek</th>\n",
       "      <th>min_watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>f6d3d8</td>\n",
       "      <td>a282ca</td>\n",
       "      <td>Factual</td>\n",
       "      <td>00:00:21</td>\n",
       "      <td>1486911129420_1</td>\n",
       "      <td>2017-02-12 14:51:24.544</td>\n",
       "      <td>20920.0</td>\n",
       "      <td>weekday_6</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.348667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>b8fbf2</td>\n",
       "      <td>e0480e</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>00:01:51</td>\n",
       "      <td>1484864257965_1</td>\n",
       "      <td>2017-01-19 22:17:04.648</td>\n",
       "      <td>111285.0</td>\n",
       "      <td>weekday_3</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.854750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>e2f113</td>\n",
       "      <td>933a1b</td>\n",
       "      <td>Factual</td>\n",
       "      <td>00:00:30</td>\n",
       "      <td>1487099603980_1</td>\n",
       "      <td>2017-02-14 19:12:36.667</td>\n",
       "      <td>29945.0</td>\n",
       "      <td>weekday_1</td>\n",
       "      <td>Evening</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.499083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>0e0916</td>\n",
       "      <td>b68e79</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>00:01:22</td>\n",
       "      <td>1484773546557_1</td>\n",
       "      <td>2017-01-18 21:05:11.466</td>\n",
       "      <td>82620.0</td>\n",
       "      <td>weekday_2</td>\n",
       "      <td>Evening</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cd2006</td>\n",
       "      <td>ca03b9</td>\n",
       "      <td>5d0813</td>\n",
       "      <td>Sport</td>\n",
       "      <td>00:01:37</td>\n",
       "      <td>1486911176609_1</td>\n",
       "      <td>2017-02-12 14:52:08.965</td>\n",
       "      <td>97444.0</td>\n",
       "      <td>weekday_6</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1.616667</td>\n",
       "      <td>3</td>\n",
       "      <td>1.624067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id program_id series_id          genre programme_duration  \\\n",
       "0  cd2006     f6d3d8    a282ca        Factual           00:00:21   \n",
       "1  cd2006     b8fbf2    e0480e         Comedy           00:01:51   \n",
       "2  cd2006     e2f113    933a1b        Factual           00:00:30   \n",
       "3  cd2006     0e0916    b68e79  Entertainment           00:01:22   \n",
       "4  cd2006     ca03b9    5d0813          Sport           00:01:37   \n",
       "\n",
       "      streaming_id         start_date_time  time_viewed    weekday  \\\n",
       "0  1486911129420_1 2017-02-12 14:51:24.544      20920.0  weekday_6   \n",
       "1  1484864257965_1 2017-01-19 22:17:04.648     111285.0  weekday_3   \n",
       "2  1487099603980_1 2017-02-14 19:12:36.667      29945.0  weekday_1   \n",
       "3  1484773546557_1 2017-01-18 21:05:11.466      82620.0  weekday_2   \n",
       "4  1486911176609_1 2017-02-12 14:52:08.965      97444.0  weekday_6   \n",
       "\n",
       "  time_of_day  programme_duration_mins  twoweek  min_watched  \n",
       "0   Afternoon                 0.350000        3     0.348667  \n",
       "1     Evening                 1.850000        1     1.854750  \n",
       "2     Evening                 0.500000        3     0.499083  \n",
       "3     Evening                 1.366667        1     1.377000  \n",
       "4   Afternoon                 1.616667        3     1.624067  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the functions to the dataframe\n",
    "data['weekday']=data['start_date_time'].apply(get_weekday)\n",
    "data['time_of_day']=data['start_date_time'].apply(get_timeofday)\n",
    "data['programme_duration_mins']=data['programme_duration'].apply(parse_programme_duration)\n",
    "data['twoweek']=data['start_date_time'].apply(get_twoweeknumber)\n",
    "\n",
    "# I noticed some negative time viewed in the data, so assume that is error and make positive\n",
    "data['time_viewed']=abs(data['time_viewed'])\n",
    "\n",
    "# Convert time viewed and length of programme into minutes\n",
    "data['min_watched']=data['time_viewed']/(60000.0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the data to make sure we don't have anything too weird happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>programme_duration_mins</th>\n",
       "      <th>twoweek</th>\n",
       "      <th>min_watched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.889520e+05</td>\n",
       "      <td>457154.000000</td>\n",
       "      <td>490852.000000</td>\n",
       "      <td>488952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.566017e+05</td>\n",
       "      <td>37.965896</td>\n",
       "      <td>4.291923</td>\n",
       "      <td>14.276694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.491019e+06</td>\n",
       "      <td>43.716212</td>\n",
       "      <td>3.490338</td>\n",
       "      <td>58.183645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.935000e+03</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.065583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.194200e+04</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.219720e+05</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.515021e+08</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>14191.701283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_viewed  programme_duration_mins        twoweek    min_watched\n",
       "count  4.889520e+05            457154.000000  490852.000000  488952.000000\n",
       "mean   8.566017e+05                37.965896       4.291923      14.276694\n",
       "std    3.491019e+06                43.716212       3.490338      58.183645\n",
       "min    0.000000e+00                 0.000000       0.000000       0.000000\n",
       "25%    3.935000e+03                 0.500000       2.000000       0.065583\n",
       "50%    8.194200e+04                30.000000       4.000000       1.365700\n",
       "75%    9.219720e+05                59.000000       6.000000      15.366200\n",
       "max    8.515021e+08               720.000000      26.000000   14191.701283"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether there is anything weird happening with our numerical values\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id - Missing: 0 - Unique: 9937\n",
      "program_id - Missing: 33698 - Unique: 23857\n",
      "series_id - Missing: 33698 - Unique: 5921\n",
      "genre - Missing: 67719 - Unique: 12\n",
      "programme_duration - Missing: 33698 - Unique: 891\n",
      "streaming_id - Missing: 0 - Unique: 434430\n",
      "start_date_time - Missing: 0 - Unique: 490626\n",
      "time_viewed - Missing: 1900 - Unique: 259529\n",
      "weekday - Missing: 0 - Unique: 7\n",
      "time_of_day - Missing: 0 - Unique: 4\n",
      "programme_duration_mins - Missing: 33698 - Unique: 891\n",
      "twoweek - Missing: 0 - Unique: 10\n",
      "min_watched - Missing: 1900 - Unique: 259529\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing and unique values there are per column\n",
    "features=data.columns.values\n",
    "for feature in features:\n",
    "    print(feature,'- Missing:', sum(data[feature].isnull()),'- Unique:', len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will want to impute the genre to reduce the amount of missing data. After that the most useful column to impute is programme_duration. <br>\n",
    "We could think about imputing series_id as well if we wanted to get really clever at a later stage. For the other missing variables imputation probably makes little sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>enriched_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001b96</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00389f</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00400b</td>\n",
       "      <td>Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00434d</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0079b7</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  series_id enriched_genre\n",
       "0    001b96        Factual\n",
       "1    00389f        Factual\n",
       "2    00400b     Children's\n",
       "3    00434d        Factual\n",
       "4    0079b7        Factual"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see whether we can guess the genre based on the series_id\n",
    "series_mapping=pd.pivot_table(data,values='streaming_id', index=['series_id'],columns=['genre'], aggfunc=len).idxmax(axis=1)\n",
    "series_mapping=pd.DataFrame(series_mapping).reset_index().rename(columns={0:'enriched_genre'})\n",
    "series_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>program_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>programme_duration</th>\n",
       "      <th>streaming_id</th>\n",
       "      <th>start_date_time</th>\n",
       "      <th>time_viewed</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>programme_duration_mins</th>\n",
       "      <th>twoweek</th>\n",
       "      <th>min_watched</th>\n",
       "      <th>enriched_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3387a6</td>\n",
       "      <td>47f8c1</td>\n",
       "      <td>c9cc1a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1485900618555_1</td>\n",
       "      <td>2017-01-31 22:10:20.049</td>\n",
       "      <td>3584.0</td>\n",
       "      <td>weekday_1</td>\n",
       "      <td>Evening</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059733</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3387a6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1489439401348_1</td>\n",
       "      <td>2017-03-13 21:10:02.421</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>weekday_0</td>\n",
       "      <td>Evening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3387a6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1485100892026_1</td>\n",
       "      <td>2017-01-22 16:01:34.292</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>weekday_6</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060567</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3387a6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1489441109070_3</td>\n",
       "      <td>2017-03-13 21:38:30.203</td>\n",
       "      <td>3651.0</td>\n",
       "      <td>weekday_0</td>\n",
       "      <td>Evening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.060850</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3387a6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1493538827057_2</td>\n",
       "      <td>2017-04-30 07:53:47.559</td>\n",
       "      <td>3665.0</td>\n",
       "      <td>weekday_6</td>\n",
       "      <td>Morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.061083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id program_id series_id genre programme_duration     streaming_id  \\\n",
       "134  3387a6     47f8c1    c9cc1a   NaN           00:00:00  1485900618555_1   \n",
       "140  3387a6        NaN       NaN   NaN                NaN  1489439401348_1   \n",
       "141  3387a6        NaN       NaN   NaN                NaN  1485100892026_1   \n",
       "142  3387a6        NaN       NaN   NaN                NaN  1489441109070_3   \n",
       "143  3387a6        NaN       NaN   NaN                NaN  1493538827057_2   \n",
       "\n",
       "            start_date_time  time_viewed    weekday time_of_day  \\\n",
       "134 2017-01-31 22:10:20.049       3584.0  weekday_1     Evening   \n",
       "140 2017-03-13 21:10:02.421       3730.0  weekday_0     Evening   \n",
       "141 2017-01-22 16:01:34.292       3634.0  weekday_6   Afternoon   \n",
       "142 2017-03-13 21:38:30.203       3651.0  weekday_0     Evening   \n",
       "143 2017-04-30 07:53:47.559       3665.0  weekday_6     Morning   \n",
       "\n",
       "     programme_duration_mins  twoweek  min_watched enriched_genre  \n",
       "134                      0.0        2     0.059733        Factual  \n",
       "140                      NaN        5     0.062167            NaN  \n",
       "141                      NaN        1     0.060567            NaN  \n",
       "142                      NaN        5     0.060850            NaN  \n",
       "143                      NaN        8     0.061083            NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's merge in the genre back into the data\n",
    "data=pd.merge(data,series_mapping,how='left',on='series_id')\n",
    "data[data['genre'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id - Missing: 0 - Unique: 9937\n",
      "program_id - Missing: 33698 - Unique: 23857\n",
      "series_id - Missing: 33698 - Unique: 5921\n",
      "genre - Missing: 67719 - Unique: 12\n",
      "programme_duration - Missing: 33698 - Unique: 891\n",
      "streaming_id - Missing: 0 - Unique: 434430\n",
      "start_date_time - Missing: 0 - Unique: 490626\n",
      "time_viewed - Missing: 1900 - Unique: 259529\n",
      "weekday - Missing: 0 - Unique: 7\n",
      "time_of_day - Missing: 0 - Unique: 4\n",
      "programme_duration_mins - Missing: 33698 - Unique: 891\n",
      "twoweek - Missing: 0 - Unique: 10\n",
      "min_watched - Missing: 1900 - Unique: 259529\n",
      "enriched_genre - Missing: 43829 - Unique: 12\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing and unique values there are per column\n",
    "features=data.columns.values\n",
    "for feature in features:\n",
    "    print(feature,'- Missing:', sum(data[feature].isnull()),'- Unique:', len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>enriched_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evening</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morning</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Night</td>\n",
       "      <td>Factual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_of_day enriched_genre\n",
       "0   Afternoon        Factual\n",
       "1     Evening        Factual\n",
       "2     Morning        Factual\n",
       "3       Night        Factual"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What genre is the most popular at which time of day\n",
    "genre_by_time=pd.pivot_table(data,values='streaming_id', index=['time_of_day'],columns=['enriched_genre'], aggfunc=len).idxmax(axis=1)\n",
    "genre_by_time=pd.DataFrame(genre_by_time).reset_index().rename(columns={0:'enriched_genre'})\n",
    "genre_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that imputes a genre based on time of day if data is missing\n",
    "def impute_genre(row):\n",
    "    if isinstance(row['genre'],str):\n",
    "        return row['genre']\n",
    "    elif isinstance(row['enriched_genre'],str):\n",
    "        return row['enriched_genre']\n",
    "    else:\n",
    "        return 'Factual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "data['enriched_genre']=data.apply(impute_genre, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether this has worked\n",
    "data[data['genre'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the average length of a programme based on genre \n",
    "length_by_genre=data.groupby('genre')['programme_duration_mins'].median()\n",
    "length_by_genre=pd.DataFrame(length_by_genre).reset_index().rename(columns={'programme_duration_mins':'enriched_duration_mins'})\n",
    "length_by_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that imputes a length of programme based on genre if data is missing\n",
    "def impute_duration(row):\n",
    "    if row['programme_duration_mins']>0:\n",
    "        return row['programme_duration_mins']\n",
    "    else:\n",
    "        if row['enriched_genre']==\"Children's\":\n",
    "            return 15.0\n",
    "        elif row['enriched_genre']==\"Comedy\":\n",
    "            return 28.0\n",
    "        elif row['enriched_genre']==\"Drama\":\n",
    "            return 45.0\n",
    "        elif row['enriched_genre']==\"Entertainment\":\n",
    "            return 30.0\n",
    "        elif row['enriched_genre']==\"Factual\":\n",
    "            return 45.0\n",
    "        elif row['enriched_genre']==\"Learning\":\n",
    "            return 10.0\n",
    "        elif row['enriched_genre']==\"Music\":\n",
    "            return 60.0\n",
    "        elif row['enriched_genre']==\"News\":\n",
    "            return 30.0\n",
    "        elif row['enriched_genre']==\"Religion & Ethics\":\n",
    "            return 60.0\n",
    "        elif row['enriched_genre']==\"Sport\":\n",
    "            return 80.0\n",
    "        elif row['enriched_genre']==\"Weather\":\n",
    "            return 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "data['enhanced_duration_mins']=data.apply(impute_duration, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether this has worked\n",
    "data[data['programme_duration_mins'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the percentage watched field from when the number is more than 100%\n",
    "def clean_perc_watched(number):\n",
    "    return min(number,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate how much of the programme the viewer watched\n",
    "data['percentage_watched']=(data['min_watched']/data['enhanced_duration_mins'])\n",
    "\n",
    "# Clean up percentaged watched from anything bigger than 100%\n",
    "data['percentage_watched']=data['percentage_watched'].apply(clean_perc_watched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is our data looking after that imputation?\n",
    "features=data.columns.values\n",
    "for feature in features:\n",
    "    print(feature,'- Missing:', sum(data[feature].isnull()),'- Unique:', len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since in Python weeks start on Monday, we will ignore the 1st of January as this was a Sunday and would give\n",
    "# us only part of a week. So we will drop that date\n",
    "data=data[data['start_date_time']>'2017-01-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of our numerical values\n",
    "data['programme_duration_mins'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['min_watched']<200]['min_watched'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['percentage_watched'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether we have more or less the same amount of data for each two week period\n",
    "data['twoweek'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of categorical values\n",
    "data['genre'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['enriched_genre'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time_of_day'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on the data above, we will drop week 0\n",
    "data=data[data['twoweek']>0]\n",
    "\n",
    "# Ensuring that we only train on the data we should have\n",
    "data_training=data[data['twoweek']<7]\n",
    "data_val=data[data['twoweek']<8]\n",
    "data_test=data[data['twoweek']==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function that pivots the data based on customer and gives us all the data we need\n",
    "def pivot_data(dataframe):\n",
    "    data=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],columns=['twoweek'], aggfunc=sum)\n",
    "    data.fillna(0,inplace=True)\n",
    "    # How much of average did each viewer watch?\n",
    "    data['average_completion']=dataframe.groupby('user_id')['percentage_watched'].mean()\n",
    "    # How many sessions did the person have with us\n",
    "    data['total_sessions']=dataframe.groupby('user_id')['streaming_id'].nunique()\n",
    "    # How much did the viewer watch in total this year sop far\n",
    "    data['total_watched']=dataframe.groupby('user_id')['min_watched'].sum()\n",
    "    # How many times has the viewer watched something\n",
    "    data['number_watched']=dataframe.groupby('user_id')['streaming_id'].count()\n",
    "    # Genre most watched by the viewer\n",
    "    data['most_genre']=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],\\\n",
    "                                         columns=['enriched_genre'], aggfunc=sum).idxmax(axis=1)\n",
    "    # Number of genres watched\n",
    "    data['num_genre']=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],\\\n",
    "                                         columns=['enriched_genre'], aggfunc=sum).count(axis=1)\n",
    "    # Favourite day of the week to watch\n",
    "    data['most_weekday']=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],\\\n",
    "                                         columns=['weekday'], aggfunc=sum).idxmax(axis=1)\n",
    "    # Number of weekdays watched\n",
    "    data['num_weekday']=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],\\\n",
    "                                         columns=['weekday'], aggfunc=sum).count(axis=1)\n",
    "    # Favorite time of day to watch\n",
    "    data['most_timeday']=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],\\\n",
    "                                         columns=['time_of_day'], aggfunc=sum).idxmax(axis=1)\n",
    "    # Number of times of day\n",
    "    data['num_timeday']=pd.pivot_table(dataframe,values='min_watched', index=['user_id'],\\\n",
    "                                         columns=['time_of_day'], aggfunc=sum).count(axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_viewer=pivot_data(data_training)\n",
    "data_viewer.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn our categorical variables into bins so that we can run models on this\n",
    "data_viewer=pd.get_dummies(data_viewer).reset_index()\n",
    "data_viewer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our target variables for our model (both the regression and the classification)\n",
    "# Need to make sure we have the same user_id's as in our feature set (and in the same order)\n",
    "target_min=pd.pivot_table(data_val,values='min_watched', index=['user_id'],columns=['twoweek'], aggfunc=sum)[7].reset_index()\n",
    "target_min=target_min.fillna(0)\n",
    "\n",
    "# Find the unique users in both the features and the target\n",
    "users_target=target_min['user_id'].unique()\n",
    "users_features=data_viewer['user_id'].unique()\n",
    "\n",
    "\n",
    "# Find those users that are in the target but not in the feature\n",
    "target_not_feature=[]\n",
    "for user in users_target:\n",
    "    if user not in users_features:\n",
    "        target_not_feature.append(user)\n",
    "\n",
    "# Find those users that are in the feature but not in the target\n",
    "feature_not_target=[]\n",
    "for user in users_features:\n",
    "    if user not in users_target:\n",
    "        feature_not_target.append(user)\n",
    "\n",
    "# Print the size of the two sets\n",
    "print('In target but not feature:',len(target_not_feature),'- In feature but not target:' ,len(feature_not_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have only issues with the target set, we will be able to just cleanse that set and don't need to worry about the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will set the index to the user_id as this will make it easier to drop rows\n",
    "# Then we drop the rows and then turn the remaining column into an array\n",
    "target_min_clean=target_min.set_index(['user_id'])\n",
    "target_min_clean.drop(target_not_feature,inplace=True)\n",
    "target_min_clean.reset_index(inplace=True)\n",
    "target_min_clean=target_min_clean[7].values\n",
    "\n",
    "# Now we create the variables for the classification\n",
    "target_class=[]\n",
    "for user in target_min_clean:\n",
    "    if user>0:\n",
    "        target_class.append(1)\n",
    "    else:\n",
    "        target_class.append(0)\n",
    "        \n",
    "# Check to make sure the outcome makes sense\n",
    "print(target_min_clean[:10])\n",
    "print(target_class[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a simple tree based classification model\n",
    "from sklearn import tree\n",
    "\n",
    "# We will use cross validation, so import helper functions for this\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's prepare the data we need\n",
    "# We will fill remaining missing values with 0s as we don't know any better\n",
    "features=data_viewer.drop(['user_id'],axis=1)\n",
    "features.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the size of our datasets\n",
    "print('Number of samples in feature set:',len(features))\n",
    "print('Number of samples in target set (classification):',len(target_class))\n",
    "print('Number of samples in target set (regression):',len(target_min_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model and develop a simple grid search against some key parameters\n",
    "param_max_depth=[3,4,6,8,10]\n",
    "param_min_leaf=[10,50,100,200]\n",
    "\n",
    "# Let's keep track of our best parameters\n",
    "best_score=0\n",
    "best_param=[0,0]\n",
    "\n",
    "\n",
    "for i in param_max_depth:\n",
    "    for j in param_min_leaf:\n",
    "        treeclass=tree.DecisionTreeClassifier(max_depth=i,min_samples_leaf=j)\n",
    "        scores=cross_val_score(treeclass,features,target_class,scoring='accuracy')\n",
    "        if np.mean(scores)>best_score:\n",
    "            best_score=np.mean(scores)\n",
    "            best_param=[i,j]\n",
    "        print('Max Depth:',i, '- Min Sample Leaf:',j)\n",
    "        print('Score:',np.mean(scores),'-',scores)\n",
    "\n",
    "# print the overall best results\n",
    "print('\\nBest Model overall:')\n",
    "print('Best Settings: Max Depth:',best_param[0], '- Min Sample Leaf:',best_param[1])\n",
    "print('Score:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a simple regression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse the features from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We setup a simple linear regression, again using cross validation\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "predicted = cross_val_predict(reg, features,target_min_clean, cv=4)\n",
    "\n",
    "# Let us plot the predicted and actual values\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target_min_clean, predicted)\n",
    "ax.plot([target_min_clean.min(), target_min_clean.max()], [target_min_clean.min(), target_min_clean.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we could also look at the score of the regression models\n",
    "cross_val_score(reg, features,target_min_clean, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks quite varied, so we probably need to put in a bit more effort into our model. <br>\n",
    "Another thing we could do at this point is to only build a regression model for the not zero values and then combine the results with our classification model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
